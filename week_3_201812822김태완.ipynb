{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qqq3964/Konkuk_NLP_Practice/blob/main/week_3_201812822%EA%B9%80%ED%83%9C%EC%99%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F24pbMKw8uT9"
      },
      "source": [
        "<h1>개인 구글 드라이브와 colab 연동</h1>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zai0Fh-g6Vf0",
        "outputId": "be853644-876d-4aa6-f504-106c44a4c672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4B-rbK8b3TW",
        "outputId": "b8f3f199-630a-4398-83f4-1264be00fc0e"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install konlpy\n",
        "\n",
        "root_dir = \"/content/drive/MyDrive/건국대NLP/4-2. Pretrained LM1\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(root_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.9/dist-packages (from konlpy) (1.22.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.9/dist-packages (from konlpy) (4.9.2)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 KB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from JPype1>=0.7.0->konlpy) (23.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdbZmdUt-d8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "6de09fd2-e367-431c-ede6-829d90207244"
      },
      "source": [
        "import os\n",
        "from IPython.display import Image\n",
        "Image(os.path.join(root_dir, \"BERT.png\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfWZLECjoJkn"
      },
      "source": [
        "<h1>BERT 모델을 이용한 감성분류</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5861idd25QB"
      },
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "\n",
        "\n",
        "class SentimentClassifier(BertPreTrainedModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(SentimentClassifier, self).__init__(config)\n",
        "\n",
        "        # BERT 모델\n",
        "        self.bert = BertModel(config)\n",
        "\n",
        "        # 히든 사이즈\n",
        "        self.hidden_size = config.hidden_size\n",
        "\n",
        "        # 분류할 라벨의 개수\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.linear = nn.Linear(in_features=self.hidden_size, out_features=self.num_labels)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        outputs = self.bert(input_ids=input_ids)\n",
        "        # (batch_size, max_length, hidden_size)\n",
        "        bert_output = outputs[0]\n",
        "\n",
        "        # (batch_size, hidden_size)\n",
        "        cls_vector = bert_output[:, 0, :] # bach_size, cls, hiddensize\n",
        "\n",
        "        # class_output : (batch_size, num_labels)\n",
        "        cls_output = self.linear(cls_vector)\n",
        "\n",
        "        return cls_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caSL4RyA1OOm"
      },
      "source": [
        "<h1>데이터 읽고 전처리 하기</h1>\n",
        "\n",
        "<pre>\n",
        "<b>1. read_data(file_path)</b>\n",
        "  \"train_datas_wordpiece.txt\", \"test_datas_wordpiece.txt\" 파일을 읽기 위한 함수\n",
        "  \n",
        "  데이터 예시)\n",
        "    ▁아 ▁더 빙 . . ▁진짜 ▁짜 증 나 네요 ▁목소리 \\t negative\n",
        "  \n",
        "  read_file(file_path)\n",
        "  args\n",
        "    file_path : 읽고자 하는 데이터의 경로\n",
        "  return\n",
        "    datas : 영화 리뷰, 정답 라벨\n",
        "    \n",
        "    출력 예시)\n",
        "      datas = [\n",
        "        (['▁아', '▁더', '빙', '.', '.', '▁진짜', '▁짜', '증', '나', '네요', '▁목소리'], negative)\n",
        "\n",
        "        (...),\n",
        "        \n",
        "        ]\n",
        "      \n",
        "<b>2. read_vocab_data(vocab_data_path)</b>\n",
        "  \"label_vocab.txt\" 파일을 읽고 라벨을 indexing하기 위한 딕셔너리를 생성\n",
        "   \n",
        "  read_vocab_data(vocab_data_path)\n",
        "  args\n",
        "    vocab_data_path : 어휘 파일 경로\n",
        "  return  \n",
        "    term2idx : 라벨을 대응하는 index로 치환하기 위한 딕셔너리\n",
        "    idx2term : index를 대응하는 라벨로 치환하기 위한 딕셔너리\n",
        "\n",
        "<b>3. convert_data2feature(datas, max_length, tokenizer, label2idx)</b>\n",
        "  입력 데이터를 고정된 길이로 변환 후 indexing\n",
        "  Tensor로 변환\n",
        "   \n",
        "  convert_data2feature(datas, max_length, tokenizer, label2idx)\n",
        "  args\n",
        "    datas : 영화 리뷰 데이터와 대응하는 정답 라벨을 갖고 있는 리스트\n",
        "    max_length : 입력의 최대 길이\n",
        "    tokenizer : electra tokenizer 객체\n",
        "    label2idx : 라벨을 대응하는 index로 치환하기 위한 딕셔너리\n",
        "  return\n",
        "    input_ids_features : 입력 문장에 대한 index sequence\n",
        "    label_id_features : 정답을 갖고 있는 리스트\n",
        "    \n",
        "  전처리 예시)\n",
        "    tokenizing된 리뷰 데이터['▁아', '▁더', '빙', '.', '.', '▁진짜', '▁짜', '증', '나', '네요', '▁목소리', ...]\n",
        "    input_ids : [2, 3360, 28709, 18, 18, 12704, 29334, ... ]\n",
        "    label_id : [1]\n",
        " </pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOGS8rse1ZZZ"
      },
      "source": [
        "import torch\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "def read_data(file_path,kom):\n",
        "    with open(file_path,'r',encoding='utf8') as Infile:\n",
        "        # line 기준으로 나누어짐\n",
        "        lines = Infile.readlines()\n",
        "\n",
        "    datas = []\n",
        "    for line in lines:\n",
        "        # tap 기준으로 parsing\n",
        "        pieces = line.strip().split(\"\\t\")\n",
        "        # 리뷰와 정답\n",
        "        input_sequence,label = pieces[0].split(\" \"),pieces[1]\n",
        "        result = []\n",
        "        for words in input_sequence:\n",
        "            target_words = kom.pos(words)\n",
        "            if len(target_words) == 2 and target_words[1][1] not in ['NNP','NP','JK','JKG','JKI','JKM','JKC','JKO','JKQ']:\n",
        "                result.append(words)\n",
        "            elif len(target_words) == 1 and target_words[0][1] not in ['NNP','NP','JK','JKG','JKI','JKM','JKC','JKO','JKQ']:\n",
        "                result.append(words)\n",
        "        datas.append((result,label))\n",
        "\n",
        "    return datas\n",
        "\n",
        "\n",
        "def read_vocab_data(vocab_data_path):\n",
        "    term2idx, idx2term = {},{}\n",
        "\n",
        "    with open(vocab_data_path, \"r\", encoding=\"utf8\") as inFile:\n",
        "        lines = inFile.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        term = line.strip()\n",
        "        term2idx[term] = len(term2idx)\n",
        "        idx2term[term2idx[term]] = term\n",
        "\n",
        "    return term2idx, idx2term\n",
        "\n",
        "\n",
        "def convert_data2feature(datas, max_length, tokenizer, label2idx):\n",
        "    input_ids_features, label_id_features = [], []\n",
        "\n",
        "    for input_sequence, label in datas:\n",
        "\n",
        "        # CLS, SEP 토큰 추가\n",
        "        tokens = [tokenizer.cls_token]\n",
        "        tokens += input_sequence\n",
        "        tokens = tokens[:max_length - 1]\n",
        "        tokens += [tokenizer.sep_token]\n",
        "\n",
        "        # word piece들을 대응하는 index로 치환\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # padding 생성\n",
        "        padding = [tokenizer._convert_token_to_id(tokenizer.pad_token)] * (max_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "\n",
        "        label_id = label2idx[label]\n",
        "\n",
        "        # 변환한 데이터를 각 리스트에 저장\n",
        "        input_ids_features.append(input_ids)\n",
        "        label_id_features.append(label_id)\n",
        "\n",
        "    # 변환한 데이터를 Tensor 객체에 담아 반환\n",
        "    input_ids_features = torch.tensor(input_ids_features, dtype=torch.long)\n",
        "    label_id_features = torch.tensor(label_id_features, dtype=torch.long)\n",
        "\n",
        "    return input_ids_features, label_id_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urLIOIHT779c"
      },
      "source": [
        "<h1>BERT 모델 학습</h1>\n",
        "\n",
        "<pre>\n",
        "<b>1. read_data(file_path) 함수를 사용하여 학습 데이터 읽기</b>\n",
        "\n",
        "<b>2. read_vocab_data(vocab_data_path) 함수를 사용하여 어휘 딕셔너리 생성</b>\n",
        "\n",
        "<b>3. convert_data2feature(datas, max_length, tokenizer, label2idx) 함수를 사용하여 데이터 전처리</b>\n",
        "\n",
        "<b>4. BERT 모델 객체 선언 후 사전 학습 파일 불러옴</b>\n",
        "\n",
        "<b>5. epoch 마다 학습한 모델 파일 저장</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsYLc2YK8eNc"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import (DataLoader, TensorDataset, RandomSampler)\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from transformers import BertConfig\n",
        "from tokenization_kobert import KoBertTokenizer\n",
        "\n",
        "\n",
        "def train(config):\n",
        "    # BERT config 객체 생성\n",
        "    bert_config = BertConfig.from_pretrained(pretrained_model_name_or_path=config[\"pretrained_model_name_or_path\"],\n",
        "                                             cache_dir=config[\"cache_dir_path\"])\n",
        "    setattr(bert_config, \"num_labels\", config[\"num_labels\"])\n",
        "\n",
        "    # BERT tokenizer 객체 생성\n",
        "    bert_tokenizer = KoBertTokenizer.from_pretrained(pretrained_model_name_or_path=config[\"pretrained_model_name_or_path\"],\n",
        "                                                     cache_dir=config[\"cache_dir_path\"])\n",
        "\n",
        "    # 라벨 딕셔너리 생성\n",
        "    label2idx, idx2label = read_vocab_data(vocab_data_path=config[\"label_vocab_data_path\"])\n",
        "\n",
        "    # 형태소 분석기\n",
        "    kom = Kkma()\n",
        "\n",
        "    # 학습 및 평가 데이터 읽기\n",
        "    train_datas = read_data(file_path=config[\"train_data_path\"],kom=kom)\n",
        "\n",
        "    # 입력 데이터 전처리\n",
        "    train_input_ids_features, train_label_id_features = convert_data2feature(datas=train_datas,\n",
        "                                                                             max_length=config[\"max_length\"],\n",
        "                                                                             tokenizer=bert_tokenizer,\n",
        "                                                                             label2idx=label2idx)\n",
        "\n",
        "    # 학습 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
        "    train_dataset = TensorDataset(train_input_ids_features, train_label_id_features)\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=config[\"batch_size\"],\n",
        "                                  sampler=RandomSampler(train_dataset))\n",
        "\n",
        "    # 사전 학습된 BERT 모델 파일로부터 가중치 불러옴\n",
        "    model = SentimentClassifier.from_pretrained(pretrained_model_name_or_path=config[\"pretrained_model_name_or_path\"],\n",
        "                                                cache_dir=config[\"cache_dir_path\"], config=bert_config).cuda()\n",
        "\n",
        "    # loss를 계산하기 위한 함수\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 모델 학습을 위한 optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "    for epoch in range(config[\"epoch\"]):\n",
        "        model.train()\n",
        "\n",
        "        total_loss = []\n",
        "        for batch in train_dataloader:\n",
        "            batch = tuple(t.cuda() for t in batch)\n",
        "            input_ids, label_id = batch\n",
        "\n",
        "            # 역전파 단계를 실행하기 전에 변화도를 0으로 변경\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 모델 예측 결과\n",
        "            hypothesis = model(input_ids)\n",
        "\n",
        "            # loss 계산\n",
        "            loss = loss_func(hypothesis, label_id)\n",
        "\n",
        "            # loss 값으로부터 모델 내부 각 매개변수에 대하여 gradient 계산\n",
        "            loss.backward()\n",
        "            # 모델 내부 각 매개변수 가중치 갱신\n",
        "            optimizer.step()\n",
        "\n",
        "            # batch 단위 loss 값 저장\n",
        "            total_loss.append(loss.data.item())\n",
        "\n",
        "        bert_config.save_pretrained(save_directory=config[\"output_dir_path\"])\n",
        "        model.save_pretrained(save_directory=config[\"output_dir_path\"])\n",
        "\n",
        "        print(\"Average loss : {}\".format(np.mean(total_loss)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20OC-TY8FIFj"
      },
      "source": [
        "<h1>BERT 모델 평가</h1>\n",
        "\n",
        "<pre>\n",
        "<b>1. read_data(file_path) 함수를 사용하여 평가 데이터 읽기</b>\n",
        "\n",
        "<b>2. read_vocab_data(vocab_data_path) 함수를 사용하여 어휘 딕셔너리 생성</b>\n",
        "\n",
        "<b>3. convert_data2feature(datas, max_length, tokenizer, label2idx) 함수를 사용하여 데이터 전처리</b>\n",
        "\n",
        "<b>4. BERT 모델 객체 선언 후 기존에 학습한 모델 파일 불러옴</b>\n",
        "\n",
        "<b>5. 학습한 BERT 모델 평가</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import (DataLoader, TensorDataset, SequentialSampler)\n",
        "\n",
        "from transformers import BertConfig\n",
        "from tokenization_kobert import KoBertTokenizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def test(config):\n",
        "    # BERT config 객체 생성\n",
        "    bert_config = BertConfig.from_pretrained(pretrained_model_name_or_path=config[\"output_dir_path\"],\n",
        "                                             cache_dir=config[\"cache_dir_path\"])\n",
        "\n",
        "    # BERT tokenizer 객체 생성 (기존 BERT tokenizer 그대로 사용)\n",
        "    bert_tokenizer = KoBertTokenizer.from_pretrained(pretrained_model_name_or_path=config[\"pretrained_model_name_or_path\"],\n",
        "                                                     cache_dir=config[\"cache_dir_path\"])\n",
        "\n",
        "    # 라벨 딕셔너리 생성\n",
        "    label2idx, idx2label = read_vocab_data(vocab_data_path=config[\"label_vocab_data_path\"])\n",
        "    \n",
        "    # 형태소 분석기\n",
        "    kom = Kkma()\n",
        "\n",
        "    # 평가 데이터 읽기\n",
        "    test_datas = read_data(file_path=config[\"test_data_path\"],kom=kom)\n",
        "    test_datas = test_datas[:100]\n",
        "\n",
        "    # 입력 데이터 전처리\n",
        "    test_input_ids_features, test_label_id_features = convert_data2feature(datas=test_datas,\n",
        "                                                                           max_length=config[\"max_length\"],\n",
        "                                                                           tokenizer=bert_tokenizer,\n",
        "                                                                           label2idx=label2idx)\n",
        "\n",
        "    # 평가 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
        "    test_dataset = TensorDataset(test_input_ids_features, test_label_id_features)\n",
        "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=config[\"batch_size\"],\n",
        "                                 sampler=SequentialSampler(test_dataset))\n",
        "\n",
        "    # 학습한 모델 파일로부터 가중치 불러옴\n",
        "    model = SentimentClassifier.from_pretrained(pretrained_model_name_or_path=config[\"output_dir_path\"],\n",
        "                                                cache_dir=config[\"cache_dir_path\"], config=bert_config).cuda()\n",
        "\n",
        "    model.eval()\n",
        "    total_hypothesis = []\n",
        "    total_label_id = []\n",
        "    pred = []\n",
        "    target = []\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.cuda() for t in batch)\n",
        "        input_ids, label_id = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # 모델 예측 결과\n",
        "            hypothesis = model(input_ids)\n",
        "            # 모델의 출력값에 softmax와 argmax 함수를 적용\n",
        "            hypothesis = torch.argmax(torch.softmax(hypothesis, dim=-1), dim=-1)\n",
        "\n",
        "        # Tensor를 리스트로 변경\n",
        "        hypothesis = hypothesis.cpu().detach().numpy().tolist()\n",
        "        label_id = label_id.cpu().detach().numpy().tolist()\n",
        "\n",
        "        for index in range(len(input_ids)):\n",
        "            input_tokens = bert_tokenizer.convert_ids_to_tokens(input_ids[index])\n",
        "            input_sequence = bert_tokenizer.convert_tokens_to_string(input_tokens[1:input_tokens.index(bert_tokenizer.sep_token)])\n",
        "            predict = idx2label[hypothesis[index]]\n",
        "            correct = idx2label[label_id[index]]\n",
        "\n",
        "            # 정답과 예측값 추가\n",
        "            pred.append(int(label2idx[predict]))\n",
        "            target.append(int(label2idx[correct]))\n",
        "    print(f'accuracy : {accuracy_score(y_pred=pred,y_true=target)}')\n"
      ],
      "metadata": {
        "id": "geme5r_us0Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 성능 평가\n",
        "\n",
        "저는 형태소 분석기를통해 고유명사와 조사들을 제거하였습니다. </br>\n",
        "형태소 분석기로는 Kkma를 이용해서 전처리 해주었습니다.</br>\n",
        "- 원래 모델 accuracy = 80프로</br>\n",
        "- 저의 모델 accuracy = 84프로"
      ],
      "metadata": {
        "id": "J99VygFipIQ2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbtyjwvtFxf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fafb3fb5-092c-479f-e4e9-e5bb4977d3cc"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "if(__name__==\"__main__\"):\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    cache_dir = os.path.join(root_dir, \"cache\")\n",
        "    \n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    if not os.path.exists(cache_dir):\n",
        "        os.makedirs(cache_dir)\n",
        "\n",
        "\n",
        "    config = {\"mode\": \"test\",\n",
        "              \"train_data_path\": os.path.join(root_dir, \"train_datas_wordpiece.txt\"),\n",
        "              \"test_data_path\": os.path.join(root_dir, \"test_datas_wordpiece.txt\"),\n",
        "              \"output_dir_path\":output_dir,\n",
        "              \"cache_dir_path\": cache_dir,\n",
        "              \"pretrained_model_name_or_path\": \"monologg/kobert\",\n",
        "              \"label_vocab_data_path\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
        "              \"num_labels\": 2,\n",
        "              \"max_length\": 142,\n",
        "              \"epoch\":10,\n",
        "              \"batch_size\":64\n",
        "              }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk-3ADInQDHZ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}